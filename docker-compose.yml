version: '3'

services:
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres_db:/var/lib/postgresql/data
      
  airflow-init:
    image: apache/airflow:2.8.1
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: admin
      _AIRFLOW_WWW_USER_PASSWORD: admin
    volumes:
      - ./dags:/opt/airflow/dags
      - ./spark_jobs:/opt/etl
    entrypoint: >
      bash -c "
        airflow db init &&
        airflow users create --username admin --password admin --firstname Revanth --lastname Reddy --role Admin --email admin@example.com"


  webserver:
    image: apache/airflow:2.8.1
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      AIRFLOW__CORE__LOAD_EXMAPLES: 'false'
    volumes:
      - ./dags:/opt/airflow/dags
      - ./spark_jobs:/opt/etl
    ports:
      - "8081:8080"
    command: webserver

  scheduler:
    image: apache/airflow:2.8.1
    depends_on:
      - webserver
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL__ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    volumes:
      - ./dags:/opt/airflow/dags
      - ./spark_jobs:/opt/etl
    command: scheduler

  spark:
    image: bitnami/spark:3.5
    environment:
      - SPARK_MODE=master
    ports:
      - "4041:4040"
    volumes:
      - ./spark_jobs:/opt/etl
volumes:
  postgres_db:
